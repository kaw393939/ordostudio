# Field Report Prompts

## Overview

Field reports are structured reflections submitted through the LMS at the end of each month. They serve two purposes: (1) force the apprentice to articulate what they are learning, and (2) generate content that feeds into the newsletter (The Ordo Brief) and marketing materials.

Each level has different prompts because the nature of the work — and the reflection — changes as the apprentice progresses.

---

## Level 1: "What did I learn?" (Months 1–3)

### Purpose
Level 1 apprentices are building foundations. Reflection at this stage is about noticing patterns, naming what is new, and developing the habit of documenting learning.

### Monthly Prompts

**Prompt 1: Models**
> What AI tools did you use this month? Describe one interaction where the AI helped and one where it misled you. What did you learn about when to trust AI output?

**Prompt 2: Key Insight**
> What is one thing you understand now that you did not understand at the beginning of the month? Explain it as if you were teaching it to someone with no technical background.

**Prompt 3: One Mistake**
> Describe a mistake you made this month — in code, in process, or in judgment. What happened? What would you do differently?

**Prompt 4: AI Interaction**
> Choose one AI Audit Log entry from this month that you are proud of. Why did you make the decision you made? What does this tell you about your developing judgment?

### Newsletter Mapping
- Prompt 1 → **Models section** (what tools are apprentices actually using?)
- Prompt 2 → **From the Field** (learning insights from the shop floor)
- Prompt 3 → **From the Field** (honest mistakes = trust-building content)
- Prompt 4 → **From the Field** (AI judgment in practice)

---

## Level 2: "What did I discover?" (Months 4–8)

### Purpose
Level 2 apprentices are investigating problems, testing assumptions, and handling failure. Reflection at this stage is about intellectual honesty — what did you assume, and what turned out to be true?

### Monthly Prompts

**Prompt 1: Problem Investigation**
> What problem did you investigate this month? What was your initial hypothesis? What evidence did you gather? Did the evidence support or challenge your hypothesis?

**Prompt 2: Assumptions Tested**
> Choose 2 entries from your Assumptions Log. For each: what did you assume? What was the reality? How did you adjust?

**Prompt 3: Surprise**
> What surprised you this month? Something in the codebase, the data, the client requirements, or your own process that you did not expect.

**Prompt 4: Resilience**
> Describe a moment this month when something broke or went wrong. How did you respond? What would a more experienced engineer have done differently?

### Newsletter Mapping
- Prompt 1 → **From the Field** (investigation stories)
- Prompt 2 → **Money section** (assumption-testing = business-relevant skill)
- Prompt 3 → **From the Field** (surprise = engagement hook)
- Prompt 4 → **People section** (resilience stories)

---

## Level 3: "What did I build?" (Months 9–14)

### Purpose
Level 3 apprentices are building systems. Reflection at this stage is about architecture, tradeoffs, and epistemic humility — what does the data actually represent, and where are the limits of what you built?

### Monthly Prompts

**Prompt 1: System Design**
> Describe the system (or subsystem) you designed this month. What were the key architectural decisions? What tradeoffs did you navigate?

**Prompt 2: Data Decisions**
> What assumptions did you make about your data this month? What can your data represent? What can it NOT represent? How do these limitations affect the system's behavior?

**Prompt 3: Tradeoff**
> Describe one significant tradeoff you made this month (performance vs. readability, speed vs. completeness, security vs. usability). What did you choose and why? What did you sacrifice?

**Prompt 4: Agent Handoff**
> If you stepped away from your project tomorrow, could someone else (or an AI agent) continue the work using only your documentation? What is missing? What would you add?

### Newsletter Mapping
- Prompt 1 → **Models section** (architecture decisions with AI)
- Prompt 2 → **From the Field** (epistemic humility in practice)
- Prompt 3 → **Money section** (tradeoff reasoning = business maturity)
- Prompt 4 → **People section** (documentation as professional skill)

---

## Level 4: "What did I ship?" (Months 15–18+)

### Purpose
Level 4 apprentices are shipping to clients and teaching communities. Reflection at this stage is strategic — what was the outcome, how did you evaluate success, and what would you do differently?

### Monthly Prompts

**Prompt 1: Client Outcome**
> What did you deliver to the client this month? How did they respond? What was the gap between what they asked for and what they actually needed?

**Prompt 2: Evaluation**
> How did you measure success this month? What metrics did you track? What do those metrics actually tell you — and what do they hide?

**Prompt 3: What I'd Do Differently**
> With hindsight, what would you change about your approach this month? Not just code changes — process, communication, prioritization, scope.

**Prompt 4: Translation**
> Describe a moment this month when you explained something technical to a non-technical audience. What worked? What didn't? What would you change?

### Newsletter Mapping
- Prompt 1 → **Money section** (client outcomes = business proof)
- Prompt 2 → **Models section** (evaluation = AI maturity signal)
- Prompt 3 → **From the Field** (honest reflection = trust)
- Prompt 4 → **People section** (translation = community building)

---

## Submission Guidelines

- **Frequency:** Monthly, due on the last day of the month
- **Length:** 200–400 words per prompt (800–1600 words total)
- **Format:** Submitted through the LMS field report system
- **Audience:** Write as if a potential client or employer will read this
- **Honesty:** Field reports that only describe successes are incomplete. The mistakes and surprises are the most valuable content.
- **Review:** Maestro reviews within 1 week and provides written feedback

## Quality Standard
A good field report is specific. "I learned about testing" is not useful. "I learned that my Copilot-generated tests were testing mocks instead of behavior when I found a bug that all 12 tests missed" is useful — to the apprentice, to the maestro, and to the newsletter reader.
