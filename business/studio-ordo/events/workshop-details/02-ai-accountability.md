# Workshop 2: AI Accountability in Practice

## Overview

| Field | Value |
|-------|-------|
| **Duration** | Half-day (3 hours) |
| **Audience** | Teams adopting AI-assisted coding |
| **Human Edge** | Professional Judgment |
| **Prerequisites** | Active use of AI coding tools (Cursor, Copilot, Claude, etc.) |
| **Max participants** | 20 |
| **Offer tier** | Offer 1 (consultation/workshop) |

## Learning Objectives

By the end of this workshop, participants will be able to:
1. Evaluate AI-generated code for correctness, security, and maintainability
2. Maintain an AI Audit Log documenting accept/reject/modify decisions with rationale
3. Identify common AI code quality issues (technical debt patterns, missing edge cases, security gaps)
4. Create a team adoption plan for the AI Audit Log practice

## Agenda

| Time | Block | Format | Description |
|------|-------|--------|-------------|
| 0:00–0:20 | The Judgment Problem | Presentation | Why AI generates with uniform confidence. The "stochastic parrot" reality. What professional judgment looks like. |
| 0:20–0:50 | Code Review Exercise (40%) | Hands-on | Review 3 AI-generated code samples. Identify correctness, security, and maintainability issues manually. No AI assistance. |
| 0:50–1:20 | AI Audit Log Introduction | Presentation + demo | The template. A complete example. Why documentation creates accountability. |
| 1:20–1:35 | Break | — | — |
| 1:35–2:20 | Pair Exercise (60%) | AI-directed | Pairs receive a task. Complete it using AI tools. Document every decision in the AI Audit Log format. Accept, reject, or modify each output with written rationale. |
| 2:20–2:45 | Audit Log Review | Group | Pairs share their most interesting decision. Group discusses patterns — what did the AI get right? What did it miss? What would have shipped without review? |
| 2:45–3:00 | Team Adoption Planning | Individual + wrap-up | Each participant drafts a 2-week plan for introducing the AI Audit Log to their team. |

## Materials

- AI Audit Log template (printable + digital)
- 3 pre-prepared AI-generated code samples (with planted issues)
- AI Audit Log adoption guide (Phase 1–3)
- Spell Book handout: Technical debt, broken windows, DRY, YAGNI, KISS, MVP, CI/CD, edge cases
- The Pragmatic Programmer key principles summary

## Artifact Produced

- Completed AI Audit Log with 5+ entries from the pair exercise
- Team adoption plan: Phase 1 (individual, week 1–2), Phase 2 (team practice, week 3–4)

## FAQ

**"This feels like overhead."**
An Audit Log entry takes 2–3 minutes. The patterns it reveals save hours of debugging. Within a month, improved Context Packs (informed by Audit Log data) produce better AI output with less review time.

**"Our team already reviews AI output."**
Review without documentation is invisible. The Audit Log makes judgment visible, shareable, and improvable.
